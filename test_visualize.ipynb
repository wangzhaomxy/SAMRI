{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Inference of the SAMRI on the nifti datasets.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from utils.visual import *\n",
    "from utils.utils import *\n",
    "from utils.dataloader import NiiDataset\n",
    "from utils.prompt import *\n",
    "from tqdm import tqdm\n",
    "from utils.losses import dice_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = [TEST_IMAGE_PATH[0]]\n",
    "test_dataset = NiiDataset(file_path, multi_mask= False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 1\n",
    "num_bboxes = 1\n",
    "jitter = JITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'samri'# Choose one from vit_b, vit_h, samri, and med_sam\n",
    "encoder_tpye = ENCODER_TYPE[model_type]\n",
    "# checkpoint = SAM_CHECKPOINT[model_type]\n",
    "checkpoint = \"/scratch/project/samri//Model_save/mult/samri_vitb_mult_45.pth\"\n",
    "device = DEVICE\n",
    "\n",
    "# regist the MRI-SAM model and predictor.\n",
    "mri_sam_model = sam_model_registry[encoder_tpye](checkpoint)\n",
    "mri_sam_model = mri_sam_model.to(device)\n",
    "mri_sam_model.eval()\n",
    "predictor = SamPredictor(mri_sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_record_samri = []\n",
    "b_record_samri = []\n",
    "\n",
    "for image, mask in tqdm(test_dataset):\n",
    "    # Image embedding inference\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    name = test_dataset.get_name()\n",
    "    mask = mask[0,:,:]\n",
    "\n",
    "    # generate prompts\n",
    "    point = gen_points(mask)\n",
    "    point_label = np.array([1])\n",
    "    points = gen_points(mask, num_points=num_points)\n",
    "    points_label = []\n",
    "    for i in range(num_points):\n",
    "        points_label += [1]\n",
    "    points_label = np.array(points_label)\n",
    "    bbox = gen_bboxes(mask, jitter=jitter)\n",
    "\n",
    "    # generate mask\n",
    "    pre_mask_p, _, _ = predictor.predict(\n",
    "                        point_coords=point,\n",
    "                        point_labels=point_label,\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "    \n",
    "    pre_mask_b, _, _ = predictor.predict(\n",
    "                        point_coords=None,\n",
    "                        point_labels=None,\n",
    "                        box=bbox[None, :],\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "\n",
    "    p_record_samri.append(dice_similarity(mask, pre_mask_p[0, :, :]))\n",
    "    b_record_samri.append(dice_similarity(mask, pre_mask_b[0, :, :]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(p_record_samri)\n",
    "plt.title(\"Point prompt, SAMRI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(b_record_samri)\n",
    "plt.title(\"BBox prompt, SAMRI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vit_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'vit_b'# Choose one from vit_b, vit_h, samri, and med_sam\n",
    "encoder_tpye = ENCODER_TYPE[model_type] \n",
    "checkpoint = SAM_CHECKPOINT[model_type]\n",
    "device = DEVICE\n",
    "\n",
    "# regist the MRI-SAM model and predictor.\n",
    "mri_sam_model = sam_model_registry[encoder_tpye](checkpoint)\n",
    "mri_sam_model = mri_sam_model.to(device)\n",
    "predictor = SamPredictor(mri_sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_record_vitb = []\n",
    "b_record_vitb = []\n",
    "\n",
    "for image, mask in tqdm(test_dataset):\n",
    "    # Image embedding inference\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    name = test_dataset.get_name()\n",
    "    mask = mask[0,:,:]\n",
    "\n",
    "    # generate prompts\n",
    "    point = gen_points(mask)\n",
    "    point_label = np.array([1])\n",
    "    points = gen_points(mask, num_points=num_points)\n",
    "    points_label = []\n",
    "    for i in range(num_points):\n",
    "        points_label += [1]\n",
    "    points_label = np.array(points_label)\n",
    "    bbox = gen_bboxes(mask, jitter=jitter)\n",
    "\n",
    "    # generate mask\n",
    "    pre_mask_p, _, _ = predictor.predict(\n",
    "                        point_coords=point,\n",
    "                        point_labels=point_label,\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "    \n",
    "    pre_mask_b, _, _ = predictor.predict(\n",
    "                        point_coords=None,\n",
    "                        point_labels=None,\n",
    "                        box=bbox[None, :],\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "\n",
    "    p_record_vitb.append(dice_similarity(mask, pre_mask_p[0, :, :]))\n",
    "    b_record_vitb.append(dice_similarity(mask, pre_mask_b[0, :, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(p_record_vitb)\n",
    "plt.title(\"Point prompt, SAM vit-b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(b_record_vitb)\n",
    "plt.title(\"BBox prompt, SAM vit-b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vit_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'vit_h'# Choose one from vit_b, vit_h, samri, and med_sam\n",
    "encoder_tpye = ENCODER_TYPE[model_type] \n",
    "checkpoint = SAM_CHECKPOINT[model_type]\n",
    "device = DEVICE\n",
    "\n",
    "# regist the MRI-SAM model and predictor.\n",
    "mri_sam_model = sam_model_registry[encoder_tpye](checkpoint)\n",
    "mri_sam_model = mri_sam_model.to(device)\n",
    "predictor = SamPredictor(mri_sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_record_vith = []\n",
    "b_record_vith = []\n",
    "\n",
    "for image, mask in tqdm(test_dataset):\n",
    "    # Image embedding inference\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    name = test_dataset.get_name()\n",
    "    mask = mask[0,:,:]\n",
    "\n",
    "    # generate prompts\n",
    "    point = gen_points(mask)\n",
    "    point_label = np.array([1])\n",
    "    points = gen_points(mask, num_points=num_points)\n",
    "    points_label = []\n",
    "    for i in range(num_points):\n",
    "        points_label += [1]\n",
    "    points_label = np.array(points_label)\n",
    "    bbox = gen_bboxes(mask, jitter=jitter)\n",
    "\n",
    "    # generate mask\n",
    "    pre_mask_p, _, _ = predictor.predict(\n",
    "                        point_coords=point,\n",
    "                        point_labels=point_label,\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "    \n",
    "    pre_mask_b, _, _ = predictor.predict(\n",
    "                        point_coords=None,\n",
    "                        point_labels=None,\n",
    "                        box=bbox[None, :],\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "\n",
    "    p_record_vith.append(dice_similarity(mask, pre_mask_p[0, :, :]))\n",
    "    b_record_vith.append(dice_similarity(mask, pre_mask_b[0, :, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(p_record_vith)\n",
    "plt.title(\"Point prompt, SAM vit-h\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(b_record_vith)\n",
    "plt.title(\"Bbox prompt, SAM vit-h\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'med_sam'# Choose one from vit_b, vit_h, samri, and med_sam\n",
    "encoder_tpye = ENCODER_TYPE[model_type] \n",
    "checkpoint = SAM_CHECKPOINT[model_type]\n",
    "device = DEVICE\n",
    "\n",
    "# regist the MRI-SAM model and predictor.\n",
    "mri_sam_model = sam_model_registry[encoder_tpye](checkpoint)\n",
    "mri_sam_model = mri_sam_model.to(device)\n",
    "predictor = SamPredictor(mri_sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_record_medsam = []\n",
    "b_record_medsam = []\n",
    "\n",
    "for image, mask in tqdm(test_dataset):\n",
    "    # Image embedding inference\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    name = test_dataset.get_name()\n",
    "    mask = mask[0,:,:]\n",
    "\n",
    "    # generate prompts\n",
    "    point = gen_points(mask)\n",
    "    point_label = np.array([1])\n",
    "    points = gen_points(mask, num_points=num_points)\n",
    "    points_label = []\n",
    "    for i in range(num_points):\n",
    "        points_label += [1]\n",
    "    points_label = np.array(points_label)\n",
    "    bbox = gen_bboxes(mask, jitter=jitter)\n",
    "\n",
    "    # generate mask\n",
    "    pre_mask_p, _, _ = predictor.predict(\n",
    "                        point_coords=point,\n",
    "                        point_labels=point_label,\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "    \n",
    "    pre_mask_b, _, _ = predictor.predict(\n",
    "                        point_coords=None,\n",
    "                        point_labels=None,\n",
    "                        box=bbox[None, :],\n",
    "                        multimask_output=False,\n",
    "                    )\n",
    "\n",
    "    p_record_medsam.append(dice_similarity(mask, pre_mask_p[0, :, :]))\n",
    "    b_record_medsam.append(dice_similarity(mask, pre_mask_b[0, :, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(p_record_medsam)\n",
    "plt.title(\"Point prompt, Med_SAM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.boxplot(b_record_medsam)\n",
    "plt.title(\"Bbox prompt, Med_SAM\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
