{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAM / SAMRI: Step-by-step Single-file Inference\n",
        "\n",
        "This notebook lets you:\n",
        "1. Load a **single input** file (NIfTI `.nii/.nii.gz` or standard image `.png/.jpg/.tif`).\n",
        "2. Normalize like your dataset (min–max → `[0,255]`, gray→RGB), producing `H×W×3` `uint8` for SAM.\n",
        "3. Register a **SAM/SAMRI** checkpoint and run inference with optional **box**/**point** prompts.\n",
        "4. Visualize the image, normalized input, and predicted mask.\n",
        "5. Save the predicted **mask** as `.nii.gz` (shape `1×H×W`) and an optional grayscale **PNG** (`H×W`).\n",
        "\n",
        "> **Note:** You need the `segment_anything` package and a valid checkpoint path to run the prediction cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Setup\n",
        "Run this cell to import dependencies and define utility functions for normalization and I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from skimage import io as skio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _to_uint8_255(arr: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Min-max normalize to [0,255] and cast to uint8 (robust to constant arrays).\"\"\"\n",
        "    arr = np.asarray(arr)\n",
        "    amin = float(arr.min())\n",
        "    amax = float(arr.max())\n",
        "    if amax > amin:\n",
        "        out = np.rint((arr - amin) / (amax - amin) * 255.0).astype(np.uint8)\n",
        "    else:\n",
        "        out = np.zeros_like(arr, dtype=np.uint8)\n",
        "    return out\n",
        "\n",
        "def _ensure_hw3_from_gray(gray_hw: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Replicate a single-channel HxW image to HxWx3 uint8.\"\"\"\n",
        "    gray_hw = np.asarray(gray_hw)\n",
        "    if gray_hw.ndim != 2:\n",
        "        raise ValueError(f\"Expected a 2D array (H,W), got shape {gray_hw.shape}.\")\n",
        "    return np.stack([gray_hw, gray_hw, gray_hw], axis=-1)\n",
        "\n",
        "def _coerce_rgb_uint8(img: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Coerce HxW / HxWx1 / HxWx3 / HxWx4 into HxWx3 uint8 in [0,255],\n",
        "    applying min-max normalization when needed.\n",
        "    \"\"\"\n",
        "    img = np.asarray(img)\n",
        "    if img.ndim == 3 and img.shape[-1] == 1:\n",
        "        img = img[..., 0]\n",
        "    if img.ndim == 2:\n",
        "        return _ensure_hw3_from_gray(_to_uint8_255(img))\n",
        "    if img.ndim == 3:\n",
        "        if img.shape[-1] == 4:\n",
        "            img = img[..., :3]  # drop alpha\n",
        "        if img.shape[-1] != 3:\n",
        "            raise ValueError(f\"Unsupported channel count {img.shape[-1]} for image input.\")\n",
        "        if img.dtype != np.uint8 or img.min() < 0 or img.max() > 255:\n",
        "            img = _to_uint8_255(img)\n",
        "        else:\n",
        "            img = img.astype(np.uint8, copy=False)\n",
        "        return img\n",
        "    raise ValueError(f\"Unsupported image array with ndim={img.ndim}, shape={img.shape}.\")\n",
        "\n",
        "def load_file(path: str):\n",
        "    \"\"\"\n",
        "    Load a single file (NIfTI .nii/.nii.gz OR standard image .png/.jpg/.tif),\n",
        "    normalize like NiiDataset (min-max → [0,255]) and return (HxWx3) uint8.\n",
        "\n",
        "    NIfTI:\n",
        "      - Expected shape: (1,H,W) or (H,W). (H,W,1) is tolerated via squeeze.\n",
        "      - Output: (H,W,3) uint8 (gray→RGB replication).\n",
        "    Image:\n",
        "      - Accepts HxW / HxWx1 / HxWx3 / HxWx4; coerces to HxWx3 uint8.\n",
        "    \"\"\"\n",
        "    lower = path.lower()\n",
        "    is_nii = lower.endswith('.nii') or lower.endswith('.nii.gz')\n",
        "\n",
        "    if is_nii:\n",
        "        img = nib.load(path)\n",
        "        data = img.get_fdata()  # float64\n",
        "        if data.ndim == 3:\n",
        "            if data.shape[0] == 1:           # (1,H,W)\n",
        "                sig = data[0, ...]\n",
        "            else:\n",
        "                if 1 in data.shape:\n",
        "                    sig = np.squeeze(data)\n",
        "                    if sig.ndim != 2:\n",
        "                        raise ValueError(f\"NIfTI squeeze did not yield 2D; got {sig.shape}.\")\n",
        "                else:\n",
        "                    raise ValueError(f\"NIfTI expected (1,H,W) or (H,W); got {data.shape}.\")\n",
        "        elif data.ndim == 2:\n",
        "            sig = data\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported NIfTI dimensionality {data.ndim}; need (1,H,W) or (H,W).\")\n",
        "\n",
        "        sig_u8 = _to_uint8_255(sig)\n",
        "        rgb = _ensure_hw3_from_gray(sig_u8)\n",
        "        info = f\"NIfTI input {data.shape} → slice {sig.shape} → output {rgb.shape} (HxWxC)\"\n",
        "        return rgb, info\n",
        "\n",
        "    # Standard image\n",
        "    img = skio.imread(path)  # HxW / HxWx3 / HxWx4\n",
        "    rgb = _coerce_rgb_uint8(img)\n",
        "    info = f\"Image input {np.asarray(img).shape} → output {rgb.shape} (HxWxC)\"\n",
        "    return rgb, info\n",
        "\n",
        "def save_mask_nii_gz(out_dir: str, base_name: str, mask_1hw: np.ndarray, affine=None, header=None) -> str:\n",
        "    \"\"\"Save mask as .nii.gz with shape [1,H,W]. Uses identity affine by default.\"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    if affine is None:\n",
        "        affine = np.eye(4)\n",
        "    nii = nib.Nifti1Image(mask_1hw.astype(np.uint8), affine=affine, header=header)\n",
        "    out_path = os.path.join(out_dir, f\"{base_name}_pred.nii.gz\")\n",
        "    nib.save(nii, out_path)\n",
        "    return out_path\n",
        "\n",
        "def save_mask_png(out_dir: str, base_name: str, mask_1hw: np.ndarray) -> str:\n",
        "    \"\"\"Save grayscale PNG (H×W) of the predicted mask (0/1 → 0/255).\"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    h, w = mask_1hw.shape[1], mask_1hw.shape[2]\n",
        "    mask_hw = (mask_1hw.reshape(h, w).astype(np.uint8)) * 255\n",
        "    out_path = os.path.join(out_dir, f\"{base_name}_pred.png\")\n",
        "    skio.imsave(out_path, mask_hw, check_contrast=False)\n",
        "    return out_path\n",
        "\n",
        "def clean_basename(inp_path: str) -> str:\n",
        "    base = os.path.basename(inp_path)\n",
        "    if base.endswith('.nii.gz'):\n",
        "        base = base[:-7]\n",
        "    else:\n",
        "        base = os.path.splitext(base)[0]\n",
        "    return base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6792f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "def gen_points(mask, num_points=1):\n",
        "    \"\"\"\n",
        "    Generate a point list [H, W] or points [[H, W], ...] in a mask.\n",
        "\n",
        "    Parameters:\n",
        "        mask (np.array): the mask in the shape of HW=(255,255) logit type\n",
        "        num_points: the number of points will be generated. If the number lager\n",
        "                    than 1, this function will return to a array listing all the \n",
        "                    points tuples in a list.\n",
        "\n",
        "    Returns:\n",
        "        (np.array): a [W, H] point List if the num_points = 1;\n",
        "        OR\n",
        "        (np.array)[[list], ...]: a list of point lists if the num_points > 1.\n",
        "    \"\"\"\n",
        "    h, w = np.nonzero(mask)\n",
        "    if num_points == 1:\n",
        "        p_idx = random.randint(int(len(h)*0.45), int(len(h)*0.55))\n",
        "        return np.array([[w[p_idx], h[p_idx]]])\n",
        "    else:\n",
        "        points = []\n",
        "        for _ in range(num_points):\n",
        "            p_idx = random.randint(int(len(h)*0.45), int(len(h)*0.55))\n",
        "            points.append([w[p_idx], h[p_idx]])\n",
        "        return np.array(points)\n",
        "    \n",
        "def gen_bboxes(mask, num_bboxes=1, jitter=0):\n",
        "    \"\"\"\n",
        "    Generate a bounding box tupple with a shape of [min_w, min_h, max_w, max_h]\n",
        "    or tupple list of multiple bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "        mask (np.array): the mask in the shape of HW=(255,255) logit type\n",
        "        num_bboxes(Tupple): the number of bounding boxes will be generated. If \n",
        "                    the number lager than 1, this function will return to a array\n",
        "                    listing all the bounding boxes tupples in a list.\n",
        "        jitter (int): the random shift of the original bounding box.\n",
        "\n",
        "    Returns:\n",
        "        (list): a [min_w, min_h, max_w, max_h] bounding box list if the\n",
        "                num_bboxes = 1;\n",
        "        [[list], ...]: a list of bounding box lists if the num_bboxes > 1. \n",
        "    \"\"\"\n",
        "    h, w = np.nonzero(mask)\n",
        "    bbox = [np.min(w), np.min(h), np.max(w), np.max(h)]\n",
        "\n",
        "    if np.max(h) - np.min(h) > jitter + 10:\n",
        "        bbox[1] = max(0, (np.min(h) + rand_shift(jitter)))\n",
        "        bbox[3] = min(mask.shape[0], (np.max(h) + rand_shift(jitter)))\n",
        "    if np.max(w) - np.min(w) > jitter + 10:\n",
        "        bbox[0] = max(0, (np.min(w) + rand_shift(jitter)))\n",
        "        bbox[2] = min(mask.shape[1], (np.max(w) + rand_shift(jitter)))\n",
        "        \n",
        "    if num_bboxes == 1:\n",
        "        return np.array(bbox)\n",
        "    else:\n",
        "        bboxes = []\n",
        "        for _ in range(num_bboxes):\n",
        "            bboxes.append(bbox)\n",
        "        return np.array(bboxes)\n",
        "\n",
        "def rand_shift(jitter):\n",
        "    \"\"\"\n",
        "    generate a random shift number from -jitter to jitter.\n",
        "\n",
        "    Parameters:\n",
        "        jitter(int): the shift number of the bbox.\n",
        "\n",
        "    Returns:\n",
        "        (int): a random shift number from -jitter to jitter\n",
        "    \"\"\"\n",
        "    return random.randint(-jitter, jitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configure paths and prompts\n",
        "Set your input path, output folder, checkpoint, and optional box/point prompts here. Then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'builtin_function_or_method' object has no attribute 'randint'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m mask, _ \u001b[38;5;241m=\u001b[39m load_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Volumes/MacMiniExtention/samri/Datasets/Shoulder/MSK_shoulder/training/Anon01_20120404_001_005_t2_trufi3d_we_cor_p2__1_1_seg_0037.nii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m BOX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m             \u001b[38;5;66;03m# e.g., [x1, y1, x2, y2]\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m BOX \u001b[38;5;241m=\u001b[39m \u001b[43mgen_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m# e.g., [x1, y1, x2, y2]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m POINT \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m           \u001b[38;5;66;03m# e.g., [x, y]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m POINT \u001b[38;5;241m=\u001b[39m gen_points(mask[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\u001b[38;5;241m0\u001b[39m])           \u001b[38;5;66;03m# e.g., [x, y]\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[5], line 49\u001b[0m, in \u001b[0;36mgen_bboxes\u001b[0;34m(mask, num_bboxes, jitter)\u001b[0m\n\u001b[1;32m     46\u001b[0m bbox \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmin(w), np\u001b[38;5;241m.\u001b[39mmin(h), np\u001b[38;5;241m.\u001b[39mmax(w), np\u001b[38;5;241m.\u001b[39mmax(h)]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(h) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(h) \u001b[38;5;241m>\u001b[39m jitter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     bbox[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, (np\u001b[38;5;241m.\u001b[39mmin(h) \u001b[38;5;241m+\u001b[39m \u001b[43mrand_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     50\u001b[0m     bbox[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], (np\u001b[38;5;241m.\u001b[39mmax(h) \u001b[38;5;241m+\u001b[39m rand_shift(jitter)))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(w) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(w) \u001b[38;5;241m>\u001b[39m jitter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
            "Cell \u001b[0;32mIn[5], line 73\u001b[0m, in \u001b[0;36mrand_shift\u001b[0;34m(jitter)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrand_shift\u001b[39m(jitter):\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    generate a random shift number from -jitter to jitter.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m        (int): a random shift number from -jitter to jitter\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m(\u001b[38;5;241m-\u001b[39mjitter, jitter)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'randint'"
          ]
        }
      ],
      "source": [
        "# --- User configuration ---\n",
        "INPUT_PATH = \"/path/to/your/input.nii.gz\"   # or .nii / .png / .jpg\n",
        "INPUT_PATH = \"/Volumes/MacMiniExtention/samri/Datasets/Shoulder/MSK_shoulder/training/Anon01_20120404_001_005_t2_trufi3d_we_cor_p2__1_1_img_0037.nii.gz\"\n",
        "OUTPUT_DIR = \"/path/to/output_folder\"\n",
        "OUTPUT_DIR = \"/Volumes/MacMiniExtention/samri/Infer_knee\"\n",
        "\n",
        "CHECKPOINT = \"/path/to/your/checkpoint.pth\"  # SAM / SAMRI checkpoint\n",
        "CHECKPOINT = \"/Volumes/MacMiniExtention/samri/models/samri_vitb_bp.pth\"\n",
        "MODEL_TYPE = \"vit_b\"  # one of: 'vit_b', 'vit_h', 'samri' (samri maps to vit_b)\n",
        "DEVICE = \"mps\"        # 'cuda' or 'cpu' or 'mps'\n",
        "\n",
        "# Optional prompts (pixel coords)\n",
        "mask, _ = load_file(\"/Volumes/MacMiniExtention/samri/Datasets/Shoulder/MSK_shoulder/training/Anon01_20120404_001_005_t2_trufi3d_we_cor_p2__1_1_seg_0037.nii.gz\")\n",
        "BOX = None             # e.g., [x1, y1, x2, y2]\n",
        "BOX = gen_bboxes(mask[...,0])             # e.g., [x1, y1, x2, y2]\n",
        "POINT = None           # e.g., [x, y]\n",
        "POINT = gen_points(mask[...,0])           # e.g., [x, y]\n",
        "SAVE_PNG = True        # also save HxW grayscale PNG\n",
        "\n",
        "BASE = clean_basename(INPUT_PATH)\n",
        "print(\"Base name:\", BASE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load input and visualize\n",
        "This cell loads the file (NIfTI or image), normalizes to `H×W×3` `uint8` like your dataset, and displays it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rgb, info = load_file(INPUT_PATH)\n",
        "print(info)\n",
        "print(\"Prepared image for SAM:\", rgb.shape, rgb.dtype)\n",
        "\n",
        "# Display the (normalized) grayscale image from channel 0\n",
        "plt.figure()\n",
        "plt.imshow(rgb[..., 0], cmap='gray')\n",
        "plt.title('Input (normalized, channel 0)')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load model\n",
        "Initialize the SAM/SAMRI model and the predictor. If the package or checkpoint are missing, you'll see a helpful error message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from segment_anything import sam_model_registry, SamPredictor\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"segment_anything is not installed in this environment.\") from e\n",
        "\n",
        "def load_sam_model(checkpoint: str, model_type: str = \"vit_b\", device: str = \"cuda\"):\n",
        "    key = \"vit_b\" if model_type.lower() in (\"vit_b\", \"samri\") else \"vit_h\"\n",
        "    model = sam_model_registry[key](checkpoint=checkpoint)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "print(\"Loading model...\")\n",
        "model = load_sam_model(CHECKPOINT, model_type=MODEL_TYPE, device=DEVICE)\n",
        "predictor = SamPredictor(model)\n",
        "print(\"Model ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run prediction\n",
        "This cell runs the predictor using your optional **box**/**point** prompts. If no prompts are provided, it uses a full-image box. The output mask has shape `1×H×W` (binary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "H, W, _ = rgb.shape\n",
        "predictor.set_image(rgb)\n",
        "\n",
        "point_coords = None\n",
        "point_labels = None\n",
        "if POINT is not None:\n",
        "    point_coords = np.array(POINT, dtype=np.float32)[None, :]\n",
        "    point_labels = np.array([1], dtype=np.int32)\n",
        "\n",
        "box_arr = None\n",
        "if BOX is not None:\n",
        "    box_arr = np.array(BOX, dtype=np.float32)[None, :]\n",
        "\n",
        "if box_arr is None and point_coords is None:\n",
        "    box_arr = np.array([[0, 0, W - 1, H - 1]], dtype=np.float32)\n",
        "\n",
        "pred_masks, _, _ = predictor.predict(\n",
        "    point_coords=point_coords,\n",
        "    point_labels=point_labels,\n",
        "    box=box_arr,\n",
        "    multimask_output=False,\n",
        ")\n",
        "\n",
        "if pred_masks.ndim == 2:\n",
        "    pred_1hw = pred_masks[None, ...]\n",
        "else:\n",
        "    pred_1hw = pred_masks[:1, ...]\n",
        "pred_1hw = (pred_1hw > 0.5).astype(np.uint8)\n",
        "print(\"Prediction mask shape:\", pred_1hw.shape, pred_1hw.dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize prediction\n",
        "Preview the predicted mask (grayscale), and also show a quick overlay on the input for sanity check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h, w = pred_1hw.shape[1], pred_1hw.shape[2]\n",
        "mask_hw = pred_1hw.reshape(h, w)\n",
        "\n",
        "# Show mask alone (grayscale)\n",
        "plt.figure()\n",
        "plt.imshow(mask_hw, cmap='gray')\n",
        "plt.title('Predicted Mask (grayscale)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Simple overlay: display input and then the mask as a separate figure\n",
        "plt.figure()\n",
        "plt.imshow(rgb[..., 0], cmap='gray')\n",
        "plt.title('Input (channel 0)')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(mask_hw, cmap='gray')\n",
        "plt.title('Mask (grayscale)')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save outputs (.nii.gz and optional PNG)\n",
        "The `.nii.gz` is saved with shape `1×H×W` using an identity affine. The PNG is a single-channel grayscale image (`H×W`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nii_path = save_mask_nii_gz(OUTPUT_DIR, BASE, pred_1hw, affine=np.eye(4), header=None)\n",
        "print(\"Saved NIfTI:\", nii_path)\n",
        "png_path = None\n",
        "if SAVE_PNG:\n",
        "    png_path = save_mask_png(OUTPUT_DIR, BASE, pred_1hw)\n",
        "    print(\"Saved PNG:\", png_path)\n",
        "print(\"Done.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. (Optional) Try different prompts\n",
        "Change `BOX` and/or `POINT` above and re-run the prediction + visualization + save cells to compare results."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "samri",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
